#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªØ·ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tavily API
ÙŠÙˆÙØ± Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª Ø¨Ø­Ø« Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©

Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
- Ø¨Ø­Ø« Ø°ÙƒÙŠ ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
- ØªØµÙÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
- Ø¯Ø¹Ù… Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
- ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
"""

import os
import json
import requests
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import re

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙƒØªØ¨Ø© python-dotenv Ù…Ø«Ø¨ØªØ©ØŒ Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù ÙŠØ¯ÙˆÙŠØ§Ù‹
    def load_env_file():
        env_file = '.env'
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
    load_env_file()

@dataclass
class SearchResult:
    """Ù†ØªÙŠØ¬Ø© Ø¨Ø­Ø« ÙˆØ§Ø­Ø¯Ø©"""
    title: str
    url: str
    content: str
    score: float
    published_date: Optional[str] = None
    domain: Optional[str] = None
    language: Optional[str] = None

@dataclass
class SearchResponse:
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
    query: str
    results: List[SearchResult]
    total_results: int
    search_time: float
    timestamp: str
    summary: Optional[str] = None

class TavilySearchEngine:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tavily API"""
    
    def __init__(self, api_key: str = None, logger=None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø«
        
        Args:
            api_key: Ù…ÙØªØ§Ø­ Tavily API
            logger: ÙƒØ§Ø¦Ù† Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        """
        self.api_key = api_key or os.getenv('TAVILY_API_KEY')
        self.logger = logger or logging.getLogger(__name__)
        
        if not self.api_key:
            raise ValueError("Ù…ÙØªØ§Ø­ Tavily API Ù…Ø·Ù„ÙˆØ¨. Ø¶Ø¹Ù‡ ÙÙŠ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© TAVILY_API_KEY")
            
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API
        self.base_url = "https://api.tavily.com"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        self.default_config = {
            "search_depth": "advanced",
            "max_results": 10,
            "include_answer": True,
            "include_raw_content": False,
            "include_domains": [],
            "exclude_domains": [],
            "topic": "general"
        }
        
    def search(self, query: str, **kwargs) -> SearchResponse:
        """
        Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
        
        Args:
            query: Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø­Ø«
            **kwargs: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¨Ø­Ø«
            
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«
        """
        start_time = datetime.now()
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        config = {**self.default_config, **kwargs}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø·Ù„Ø¨ Ø§Ù„Ø¨Ø­Ø«
        search_request = {
            "query": query,
            "search_depth": config["search_depth"],
            "max_results": config["max_results"],
            "include_answer": config["include_answer"],
            "include_raw_content": config["include_raw_content"],
            "topic": config["topic"]
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
        if config["include_domains"]:
            search_request["include_domains"] = config["include_domains"]
        if config["exclude_domains"]:
            search_request["exclude_domains"] = config["exclude_domains"]
            
        try:
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
            response = requests.post(
                f"{self.base_url}/search",
                headers=self.headers,
                json=search_request,
                timeout=30
            )
            
            response.raise_for_status()
            data = response.json()
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            results = []
            for item in data.get("results", []):
                result = SearchResult(
                    title=item.get("title", ""),
                    url=item.get("url", ""),
                    content=item.get("content", ""),
                    score=item.get("score", 0.0),
                    published_date=item.get("published_date"),
                    domain=self._extract_domain(item.get("url", "")),
                    language=self._detect_language(item.get("content", ""))
                )
                results.append(result)
                
            # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„Ø¨Ø­Ø«
            search_time = (datetime.now() - start_time).total_seconds()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            search_response = SearchResponse(
                query=query,
                results=results,
                total_results=len(results),
                search_time=search_time,
                timestamp=datetime.now().isoformat(),
                summary=data.get("answer")
            )
            
            self.logger.info(f"ğŸ” ØªÙ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: '{query}' - {len(results)} Ù†ØªÙŠØ¬Ø© ÙÙŠ {search_time:.2f}s")
            
            return search_response
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
            raise
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
            raise
            
    def search_quran_related(self, query: str, **kwargs) -> SearchResponse:
        """
        Ø¨Ø­Ø« Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
        
        Args:
            query: Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø­Ø«
            **kwargs: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªØ®ØµØµØ©
        """
        # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ©
        enhanced_query = f"{query} Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… ØªÙØ³ÙŠØ±"
        
        # Ù…Ø¬Ø§Ù„Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
        trusted_domains = [
            "islamweb.net",
            "alukah.net",
            "islamqa.info",
            "dorar.net",
            "quran.com",
            "tanzil.net"
        ]
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªØ®ØµØµØ©
        config = {
            "include_domains": trusted_domains,
            "search_depth": "advanced",
            "max_results": 15,
            **kwargs
        }
        
        return self.search(enhanced_query, **config)
        
    def search_academic(self, query: str, **kwargs) -> SearchResponse:
        """
        Ø¨Ø­Ø« Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ù…ØªØ®ØµØµ
        
        Args:
            query: Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø­Ø«
            **kwargs: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©
        """
        # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©
        academic_query = f"{query} research paper academic study"
        
        # Ù…Ø¬Ø§Ù„Ø§Øª Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©
        academic_domains = [
            "scholar.google.com",
            "researchgate.net",
            "academia.edu",
            "jstor.org",
            "springer.com",
            "ieee.org"
        ]
        
        config = {
            "include_domains": academic_domains,
            "search_depth": "advanced",
            "max_results": 20,
            **kwargs
        }
        
        return self.search(academic_query, **config)
        
    def _extract_domain(self, url: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ø§Ù„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
        try:
            from urllib.parse import urlparse
            return urlparse(url).netloc
        except:
            return ""
            
    def _detect_language(self, text: str) -> str:
        """ÙƒØ´Ù Ù„ØºØ© Ø§Ù„Ù†Øµ (Ø¨Ø³ÙŠØ·)"""
        if not text:
            return "unknown"
            
        # Ø¹Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        arabic_chars = len(re.findall(r'[\u0600-\u06FF]', text))
        total_chars = len(re.findall(r'[a-zA-Z\u0600-\u06FF]', text))
        
        if total_chars == 0:
            return "unknown"
            
        arabic_ratio = arabic_chars / total_chars
        
        if arabic_ratio > 0.3:
            return "arabic"
        else:
            return "english"
            
    def summarize_results(self, search_response: SearchResponse, max_length: int = 500) -> str:
        """
        ØªÙ„Ø®ÙŠØµ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«
        
        Args:
            search_response: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«
            max_length: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ù„Ø®Øµ
            
        Returns:
            Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        if search_response.summary:
            return search_response.summary[:max_length]
            
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        all_content = []
        for result in search_response.results[:5]:  # Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬
            if result.content:
                all_content.append(result.content[:200])
                
        combined_content = " ".join(all_content)
        
        # ØªÙ‚ØµÙŠØ± Ø§Ù„Ù…Ù„Ø®Øµ
        if len(combined_content) > max_length:
            combined_content = combined_content[:max_length] + "..."
            
        return combined_content
        
    def export_results(self, search_response: SearchResponse, output_file: str):
        """
        ØªØµØ¯ÙŠØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¥Ù„Ù‰ Ù…Ù„Ù
        
        Args:
            search_response: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«
            output_file: Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        """
        export_data = {
            "query": search_response.query,
            "timestamp": search_response.timestamp,
            "total_results": search_response.total_results,
            "search_time": search_response.search_time,
            "summary": search_response.summary,
            "results": [
                {
                    "title": result.title,
                    "url": result.url,
                    "content": result.content,
                    "score": result.score,
                    "domain": result.domain,
                    "language": result.language
                }
                for result in search_response.results
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
            
        self.logger.info(f"ğŸ“„ ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰: {output_file}")

# Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    import sys
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    logging.basicConfig(level=logging.INFO)
    
    if len(sys.argv) < 2:
        print("Usage: python search_engine.py <search_query>")
        sys.exit(1)
        
    query = " ".join(sys.argv[1:])
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø«
        search_engine = TavilySearchEngine()
        
        # Ø§Ù„Ø¨Ø­Ø«
        results = search_engine.search(query)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print(f"\nğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: '{query}'")
        print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {results.total_results}")
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ø¨Ø­Ø«: {results.search_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        
        if results.summary:
            print(f"\nğŸ“ Ø§Ù„Ù…Ù„Ø®Øµ: {results.summary}")
            
        print("\nğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        for i, result in enumerate(results.results[:5], 1):
            print(f"\n{i}. {result.title}")
            print(f"   ğŸ”— {result.url}")
            print(f"   ğŸ“„ {result.content[:200]}...")
            print(f"   â­ Ø§Ù„Ù†Ù‚Ø§Ø·: {result.score:.2f}")
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
        sys.exit(1)
