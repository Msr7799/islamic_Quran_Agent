#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ูุณุชุฎุฑุฌ ุฅุญุฏุงุซูุงุช ุงูุขูุงุช ุจุงุณุชุฎุฏุงู OCR ููุนุงูุฌุฉ SVG ุงููุญุณูุฉ
ูุฏุนู ุงุณุชุฎุฑุงุฌ ุงููุตูุต ูู SVG ูุน ูุนุงูุฌุฉ ุงููุณุงูุงุช ูุงูุชุทุจูุน ุงููุชูุฏู
"""

import json
import re
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import xml.etree.ElementTree as ET
import pandas as pd
import unicodedata
from difflib import SequenceMatcher
import subprocess
from PIL import Image
import pytesseract

def normalize_unicode_text_advanced(text):
    """ุชุทุจูุน ุงููุต ุงูุนุฑุจู ุงููุญุณู ูุน ูุนุงูุฌุฉ ุงููุณุงูุงุช"""
    if not text:
        return ""

    # ุชุทุจูุน Unicode ูุชูุฏู
    text = unicodedata.normalize('NFKC', text)

    # ูุนุงูุฌุฉ ุงููุณุงูุงุช ุงููุฎุชููุฉ
    space_chars = {
        '\u0020': ' ',  # ูุณุงูุฉ ุนุงุฏูุฉ
        '\u00A0': ' ',  # ูุณุงูุฉ ุบูุฑ ูููุณูุฉ
        '\u2000': ' ',  # en quad
        '\u2001': ' ',  # em quad
        '\u2002': ' ',  # en space
        '\u2003': ' ',  # em space
        '\u2004': ' ',  # three-per-em space
        '\u2005': ' ',  # four-per-em space
        '\u2006': ' ',  # six-per-em space
        '\u2007': ' ',  # figure space
        '\u2008': ' ',  # punctuation space
        '\u2009': ' ',  # thin space
        '\u200A': ' ',  # hair space
        '\u202F': ' ',  # narrow no-break space
        '\u205F': ' ',  # medium mathematical space
        '\u3000': ' ',  # ideographic space
        '\t': ' ',      # tab
        '\n': ' ',      # newline
        '\r': ' ',      # carriage return
    }

    # ุงุณุชุจุฏุงู ุฌููุน ุฃููุงุน ุงููุณุงูุงุช ุจูุณุงูุฉ ุนุงุฏูุฉ
    for space_char, replacement in space_chars.items():
        text = text.replace(space_char, replacement)

    # ุชูุธูู ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ
    text = re.sub(r'\s+', ' ', text)

    # ุงุณุชุจุฏุงู ุงูุฃุญุฑู ุงููุชุดุงุจูุฉ ูุงููุชุบูุฑุงุช ุงูุนุซูุงููุฉ
    replacements = {
        # ุงูุฃูู ูุฃุดูุงููุง ุงูุนุซูุงููุฉ
        'ูฑ': 'ุง',  # ุฃูู ูุตู
        'ุฃ': 'ุง',  # ููุฒุฉ ุนูู ุฃูู
        'ุฅ': 'ุง',  # ููุฒุฉ ุชุญุช ุฃูู
        'ุข': 'ุง',  # ูุฏ ุนูู ุฃูู
        '๏บ': 'ุง', '๏บ': 'ุง',  # ุฃุดูุงู ุงูุฃูู ุงููุฎุชููุฉ

        # ุงูููุฒุฉ ูุฃุดูุงููุง
        'ุค': 'ู',  # ููุฒุฉ ุนูู ูุงู
        'ุฆ': 'ู',  # ููุฒุฉ ุนูู ูุงุก
        'ุก': '',   # ููุฒุฉ ูููุฑุฏุฉ (ุชูุญุฐู ูู ุงููุทุงุจูุฉ)

        # ุงููุงุก ูุงูุฃูู ุงูููุตูุฑุฉ
        'ู': 'ู',  # ุฃูู ููุตูุฑุฉ
        '๏ปฏ': 'ู', '๏ปฐ': 'ู', '๏ปฑ': 'ู', '๏ปฒ': 'ู',  # ุฃุดูุงู ุงููุงุก

        # ุงูุชุงุก ุงููุฑุจูุทุฉ ูุงููุงุก
        'ุฉ': 'ู',  # ุชุงุก ูุฑุจูุทุฉ
        '๏บ': 'ู', '๏บ': 'ู',  # ุฃุดูุงู ุงูุชุงุก ุงููุฑุจูุทุฉ

        # ุงููุงู ูุฃุดูุงููุง
        '๏ปญ': 'ู', '๏ปฎ': 'ู',  # ุฃุดูุงู ุงููุงู
    }

    # ุชุทุจูู ุงูุงุณุชุจุฏุงูุงุช
    for old_char, new_char in replacements.items():
        text = text.replace(old_char, new_char)

    return text.strip()

class AdvancedFontMatcher:
    """ูุทุงุจู ูุชูุฏู ุจุงุณุชุฎุฏุงู ุฌุฏูู ุงูุฎุท ูุน ูุนุงูุฌุฉ OCR"""

    def __init__(self, font_mapping_file="uthmani_font_mapping.json"):
        self.font_data = self.load_font_mapping(font_mapping_file)
        self.character_map = self.font_data.get('character_map', {})
        self.reverse_mapping = self.font_data.get('reverse_mapping', {})
        self.normalization_rules = self.font_data.get('normalization_rules', {})
        
    def load_font_mapping(self, mapping_file):
        """ุชุญููู ุฌุฏูู ุงูุฎุท"""
        if not os.path.exists(mapping_file):
            print(f"ุชุญุฐูุฑ: ููู ุฌุฏูู ุงูุฎุท ุบูุฑ ููุฌูุฏ: {mapping_file}")
            return {'character_map': {}, 'reverse_mapping': {}, 'normalization_rules': {}}
        
        try:
            with open(mapping_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ุฎุทุฃ ูู ุชุญููู ุฌุฏูู ุงูุฎุท: {e}")
            return {'character_map': {}, 'reverse_mapping': {}, 'normalization_rules': {}}
    
    def normalize_text_precise(self, text):
        """ุชุทุจูุน ุงููุต ุจุงุณุชุฎุฏุงู ุฌุฏูู ุงูุฎุท"""
        if not text:
            return ""
        
        normalized = ""
        for char in text:
            # ุงุณุชุฎุฏุงู ููุงุนุฏ ุงูุชุทุจูุน ูู ุฌุฏูู ุงูุฎุท
            normalized_char = self.normalization_rules.get(char, char)
            normalized += normalized_char
        
        return normalized
    
    def remove_all_diacritics_precise(self, text):
        """ุฅุฒุงูุฉ ุฌููุน ุงูุฑููุฒ ุงูุนุซูุงููุฉ ุจุงุณุชุฎุฏุงู ุฌุฏูู ุงูุฎุท"""
        if not text:
            return ""
        
        cleaned = ""
        for char in text:
            char_info = self.character_map.get(char, {})
            # ุฅุฐุง ูุงู ุงูุญุฑู ุฑูุฒ ุนุซูุงููุ ุชุฌุงููู
            if char_info.get('is_symbol', False):
                continue
            # ุฅุฐุง ูุงู ุญุฑู ุฃุณุงุณูุ ุฃุถูู
            cleaned += char
        
        return cleaned
    
    def get_character_variants(self, base_char):
        """ุงูุญุตูู ุนูู ุฌููุน ุฃุดูุงู ุงูุญุฑู"""
        return self.reverse_mapping.get(base_char, [base_char])
    
    def calculate_precise_similarity(self, text1, text2):
        """ุญุณุงุจ ุงูุชุดุงุจู ุงูุฏููู ุจุงุณุชุฎุฏุงู ุฌุฏูู ุงูุฎุท"""
        # ุชุทุจูุน ุงููุตูุต
        norm1 = self.normalize_text_precise(text1)
        norm2 = self.normalize_text_precise(text2)
        
        # ุฅุฒุงูุฉ ุงูุฑููุฒ ุงูุนุซูุงููุฉ
        clean1 = self.remove_all_diacritics_precise(norm1)
        clean2 = self.remove_all_diacritics_precise(norm2)
        
        # ุญุณุงุจ ุงูุชุดุงุจู
        if not clean1 or not clean2:
            return 0.0
        
        if clean1 == clean2:
            return 1.0
        
        # ุญุณุงุจ ุงูุชุดุงุจู ุงูุฌุฒุฆู
        matches = 0
        total = max(len(clean1), len(clean2))
        
        for i in range(min(len(clean1), len(clean2))):
            if clean1[i] == clean2[i]:
                matches += 1
        
        return matches / total if total > 0 else 0.0

class PreciseAyatExtractor:
    """ูุณุชุฎุฑุฌ ุฏููู ูุฅุญุฏุงุซูุงุช ุงูุขูุงุช"""
    
    def __init__(self, font_mapping_file="uthmani_font_mapping.json"):
        self.font_matcher = PreciseFontMatcher(font_mapping_file)
        
    def extract_text_from_svg(self, svg_file):
        """ุงุณุชุฎุฑุงุฌ ุงููุตูุต ูู ููู SVG (ูุฏุนู ุงููุตูุต ูุงููุณุงุฑุงุช)"""
        try:
            tree = ET.parse(svg_file)
            root = tree.getroot()

            texts = []

            # ุงูุจุญุซ ุนู ุนูุงุตุฑ ุงููุต ุงููุจุงุดุฑุฉ
            for elem in root.iter():
                if elem.tag.endswith('text') or elem.tag.endswith('tspan'):
                    if elem.text:
                        x = elem.get('x', '0')
                        y = elem.get('y', '0')

                        texts.append({
                            'text': elem.text.strip(),
                            'x': float(x) if x.replace('.', '').replace('-', '').isdigit() else 0,
                            'y': float(y) if y.replace('.', '').replace('-', '').isdigit() else 0,
                            'type': 'direct_text'
                        })

            # ุฅุฐุง ูู ูุฌุฏ ูุตูุต ูุจุงุดุฑุฉุ ูุญุงูู ุงุณุชุฎุฑุงุฌ ูู ุงููุณุงุฑุงุช
            if not texts:
                print(f"  ูุง ุชูุฌุฏ ูุตูุต ูุจุงุดุฑุฉุ ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ ูู ุงููุณุงุฑุงุช...")
                texts = self.extract_from_svg_paths(root)

            return texts

        except Exception as e:
            print(f"ุฎุทุฃ ูู ูุฑุงุกุฉ ููู SVG: {e}")
            return []

    def extract_from_svg_paths(self, root):
        """ุงุณุชุฎุฑุงุฌ ุงููุตูุต ูู ูุณุงุฑุงุช SVG (ุชุฌุฑูุจู)"""
        texts = []

        # ุงูุจุญุซ ุนู ุนูุงุตุฑ use ุงูุชู ุชุดูุฑ ุฅูู ุงูุฃุญุฑู
        for elem in root.iter():
            if elem.tag.endswith('use'):
                href = elem.get('{http://www.w3.org/1999/xlink}href') or elem.get('href')
                if href and href.startswith('#font_'):
                    x = elem.get('x', '0')
                    y = elem.get('y', '0')

                    # ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ ูุนุฑู ุงูุญุฑู ูู href
                    font_id = href.replace('#', '')

                    texts.append({
                        'text': self.decode_font_id(font_id),
                        'x': float(x) if x.replace('.', '').replace('-', '').isdigit() else 0,
                        'y': float(y) if y.replace('.', '').replace('-', '').isdigit() else 0,
                        'type': 'font_path',
                        'font_id': font_id
                    })

        # ุฅุฐุง ูู ูุฌุฏ ุนูุงุตุฑ useุ ูุญุงูู ุทุฑููุฉ ุฃุฎุฑู
        if not texts:
            # ุงูุจุญุซ ุนู ูุฌููุนุงุช (groups) ูุฏ ุชุญุชูู ุนูู ูุตูุต
            for elem in root.iter():
                if elem.tag.endswith('g'):  # group
                    # ูุญุต ุฅุฐุง ูุงูุช ุงููุฌููุนุฉ ุชุญุชูู ุนูู ูุณุงุฑุงุช ูุต
                    paths_in_group = [child for child in elem if child.tag.endswith('path')]
                    if paths_in_group:
                        # ุงุณุชุฎุฑุงุฌ ุงูุฅุญุฏุงุซูุงุช ูู transform ุฃู ูู ุฃูู ูุณุงุฑ
                        transform = elem.get('transform', '')
                        x, y = self.extract_coordinates_from_transform(transform)

                        texts.append({
                            'text': f"[ูุฌููุนุฉ_{len(texts)+1}]",  # ูุต ุชุฌุฑูุจู
                            'x': x,
                            'y': y,
                            'type': 'group_paths',
                            'paths_count': len(paths_in_group)
                        })

        return texts

    def decode_font_id(self, font_id):
        """ูุญุงููุฉ ูู ุชุดููุฑ ูุนุฑู ุงูุฎุท ุฅูู ุญุฑู"""
        # ูุฐู ุทุฑููุฉ ุชุฌุฑูุจูุฉ - ูุฏ ูุญุชุงุฌ ูุชุญุณูููุง
        if 'font_' in font_id:
            # ุงุณุชุฎุฑุงุฌ ุงูุฑูู ูู ูุนุฑู ุงูุฎุท
            parts = font_id.split('_')
            if len(parts) >= 3:
                try:
                    char_code = int(parts[2])
                    # ูุญุงููุฉ ุชุญููู ุฅูู ุญุฑู Unicode
                    if char_code < 1000:  # ุฃุฑูุงู ุจุณูุทุฉ
                        return str(char_code)
                    else:
                        return chr(char_code) if char_code < 65536 else f"[{char_code}]"
                except:
                    return f"[{font_id}]"
        return f"[{font_id}]"

    def extract_coordinates_from_transform(self, transform):
        """ุงุณุชุฎุฑุงุฌ ุงูุฅุญุฏุงุซูุงุช ูู ุฎุงุตูุฉ transform"""
        x, y = 0, 0
        if 'translate' in transform:
            import re
            match = re.search(r'translate\(([^)]+)\)', transform)
            if match:
                coords = match.group(1).split(',')
                try:
                    x = float(coords[0].strip())
                    y = float(coords[1].strip()) if len(coords) > 1 else 0
                except:
                    pass
        return x, y
    
    def find_verse_numbers_precise(self, texts):
        """ุงูุจุญุซ ุนู ุฃุฑูุงู ุงูุขูุงุช ุจุฏูุฉ"""
        verse_numbers = []
        
        # ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ ูุงูุฅูุฌููุฒูุฉ
        arabic_digits = 'ููกูขูฃูคูฅูฆูงูจูฉ'
        english_digits = '0123456789'
        
        for text_info in texts:
            text = text_info['text']
            
            # ุงูุจุญุซ ุนู ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ
            arabic_match = re.search(f'[{arabic_digits}]+', text)
            if arabic_match:
                arabic_num = arabic_match.group()
                # ุชุญููู ุฅูู ุฅูุฌููุฒู
                english_num = ""
                for char in arabic_num:
                    if char in arabic_digits:
                        english_num += str(arabic_digits.index(char))
                
                if english_num.isdigit():
                    verse_numbers.append({
                        'number': int(english_num),
                        'arabic_text': arabic_num,
                        'x': text_info['x'],
                        'y': text_info['y'],
                        'full_text': text
                    })
            
            # ุงูุจุญุซ ุนู ุงูุฃุฑูุงู ุงูุฅูุฌููุฒูุฉ
            english_match = re.search(f'[{english_digits}]+', text)
            if english_match:
                english_num = english_match.group()
                if english_num.isdigit():
                    verse_numbers.append({
                        'number': int(english_num),
                        'arabic_text': english_num,
                        'x': text_info['x'],
                        'y': text_info['y'],
                        'full_text': text
                    })
        
        return verse_numbers
    
    def match_verses_with_reference_precise(self, extracted_texts, reference_verses):
        """ูุทุงุจูุฉ ุงูุขูุงุช ูุน ุงููุฑุฌุน ุจุฏูุฉ 100%"""
        results = []
        
        for verse_num, reference_text in reference_verses.items():
            best_match = None
            best_similarity = 0.0
            
            for text_info in extracted_texts:
                similarity = self.font_matcher.calculate_precise_similarity(
                    text_info['text'], reference_text
                )
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = text_info
            
            if best_match and best_similarity > 0.8:  # ุนุชุจุฉ ุนุงููุฉ ููุฏูุฉ
                results.append({
                    'verse_number': verse_num,
                    'reference_text': reference_text,
                    'extracted_text': best_match['text'],
                    'similarity': best_similarity,
                    'coordinates': {
                        'x': best_match['x'],
                        'y': best_match['y']
                    },
                    'match_quality': 'excellent' if best_similarity > 0.95 else 'good'
                })
        
        return results
    
    def process_page_precise(self, svg_file, reference_verses):
        """ูุนุงูุฌุฉ ุตูุญุฉ ูุงุญุฏุฉ ุจุฏูุฉ"""
        print(f"ูุนุงูุฌุฉ ุงูููู: {svg_file}")
        
        # ุงุณุชุฎุฑุงุฌ ุงููุตูุต
        extracted_texts = self.extract_text_from_svg(svg_file)
        print(f"ุชู ุงุณุชุฎุฑุงุฌ {len(extracted_texts)} ูุต")
        
        # ุงูุจุญุซ ุนู ุฃุฑูุงู ุงูุขูุงุช
        verse_numbers = self.find_verse_numbers_precise(extracted_texts)
        print(f"ุชู ุงูุนุซูุฑ ุนูู {len(verse_numbers)} ุฑูู ุขูุฉ")
        
        # ูุทุงุจูุฉ ุงูุขูุงุช
        matched_verses = self.match_verses_with_reference_precise(extracted_texts, reference_verses)
        print(f"ุชู ูุทุงุจูุฉ {len(matched_verses)} ุขูุฉ")
        
        return {
            'file': svg_file,
            'extracted_texts': extracted_texts,
            'verse_numbers': verse_numbers,
            'matched_verses': matched_verses,
            'statistics': {
                'total_texts': len(extracted_texts),
                'verse_numbers_found': len(verse_numbers),
                'verses_matched': len(matched_verses),
                'accuracy': len(matched_verses) / len(reference_verses) * 100 if reference_verses else 0
            }
        }

def load_reference_verses(reference_file):
    """ุชุญููู ุงูุขูุงุช ุงููุฑุฌุนูุฉ"""
    if not os.path.exists(reference_file):
        print(f"ููู ุงููุฑุฌุน ุบูุฑ ููุฌูุฏ: {reference_file}")
        return {}
    
    try:
        with open(reference_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"ุฎุทุฃ ูู ุชุญููู ุงููุฑุฌุน: {e}")
        return {}

def create_sample_reference():
    """ุฅูุดุงุก ูุฑุฌุน ุชุฌุฑูุจู ููุงุฎุชุจุงุฑ"""
    sample_verses = {
        1: "ุจูุณกูู ูฑูููููู ูฑูุฑููุญกูููฐูู ูฑูุฑููุญูููู",
        2: "ูฑูกุญููกุฏู ููููููู ุฑูุจูู ูฑูกุนููฐููููููู",
        3: "ูฑูุฑููุญกูููฐูู ูฑูุฑููุญูููู",
        4: "ูููฐูููู ูููกูู ูฑูุฏููููู",
        5: "ุฅููููุงูู ููุนกุจูุฏู ููุฅููููุงูู ููุณกุชูุนูููู",
        6: "ูฑูกุฏูููุง ูฑูุตููุฑููฐุทู ูฑูกููุณกุชูููููู",
        7: "ุตูุฑููฐุทู ูฑูููุฐูููู ุฃููกุนููกุชู ุนููููกูููก ุบููกุฑู ูฑูกููุบกุถููุจู ุนููููกูููก ููููุง ูฑูุถููุขูููููู"
    }

    with open("reference_verses.json", 'w', encoding='utf-8') as f:
        json.dump(sample_verses, f, ensure_ascii=False, indent=2)

    print("ุชู ุฅูุดุงุก ููู ูุฑุฌุนู ุชุฌุฑูุจู: reference_verses.json")
    return sample_verses

def main():
    """ุงููุธููุฉ ุงูุฑุฆูุณูุฉ"""
    print("ูุณุชุฎุฑุฌ ุฅุญุฏุงุซูุงุช ุงูุขูุงุช ุจุฏูุฉ 100%")
    print("ูุณุชุฎุฏู ุฌุฏูู ุงูุฎุท ุงูุนุซูุงูู ูููุทุงุจูุฉ ุงูุฏูููุฉ")
    print("=" * 60)

    # ุฅูุดุงุก ุฌุฏูู ุงูุฎุท ุฅุฐุง ูู ููู ููุฌูุฏุงู
    font_mapping_file = "uthmani_font_mapping.json"
    if not os.path.exists(font_mapping_file):
        print("ุฅูุดุงุก ุฌุฏูู ุงูุฎุท ุงูุนุซูุงูู...")
        try:
            import subprocess
            result = subprocess.run(["python", "font_mapping_extractor.py"],
                                  capture_output=True, text=True)
            if result.returncode != 0:
                print("ุชุญุฐูุฑ: ูุดู ูู ุฅูุดุงุก ุฌุฏูู ุงูุฎุท")
        except:
            print("ุชุญุฐูุฑ: ูู ูุชู ุฅูุดุงุก ุฌุฏูู ุงูุฎุท")

    # ุฅูุดุงุก ุงููุณุชุฎุฑุฌ ุงูุฏููู
    extractor = PreciseAyatExtractor(font_mapping_file)

    # ุชุญููู ุฃู ุฅูุดุงุก ุงููุฑุฌุน
    reference_verses = load_reference_verses("reference_verses.json")
    if not reference_verses:
        print("ุฅูุดุงุก ูุฑุฌุน ุชุฌุฑูุจู...")
        reference_verses = create_sample_reference()

    print(f"ุชู ุชุญููู {len(reference_verses)} ุขูุฉ ูุฑุฌุนูุฉ")

    # ูุนุงูุฌุฉ ุงููููุงุช
    svg_files = list(Path(".").glob("*.svg"))
    if not svg_files:
        # ุงูุจุญุซ ูู ูุฌูุฏ pages_svgs
        svg_files = list(Path("pages_svgs").glob("*.svg"))
        if not svg_files:
            print("ูุง ุชูุฌุฏ ูููุงุช SVG ูููุนุงูุฌุฉ")
            print("ุชุฃูุฏ ูู ูุฌูุฏ ูููุงุช SVG ูู ุงููุฌูุฏ ุงูุญุงูู ุฃู ูุฌูุฏ pages_svgs")
            return 1
        else:
            print(f"ุชู ุงูุนุซูุฑ ุนูู ูููุงุช SVG ูู ูุฌูุฏ pages_svgs")

    print(f"ุชู ุงูุนุซูุฑ ุนูู {len(svg_files)} ููู SVG")

    all_results = []
    processed_count = 0

    for svg_file in svg_files[:5]:  # ูุนุงูุฌุฉ ุฃูู 5 ูููุงุช ููุงุฎุชุจุงุฑ
        try:
            result = extractor.process_page_precise(str(svg_file), reference_verses)
            all_results.append(result)
            processed_count += 1

            print(f"ุงูููู: {svg_file.name}")
            print(f"  ุงููุตูุต ุงููุณุชุฎุฑุฌุฉ: {result['statistics']['total_texts']}")
            print(f"  ุฃุฑูุงู ุงูุขูุงุช: {result['statistics']['verse_numbers_found']}")
            print(f"  ุงูุขูุงุช ุงููุทุงุจูุฉ: {result['statistics']['verses_matched']}")
            print(f"  ุฏูุฉ ุงููุทุงุจูุฉ: {result['statistics']['accuracy']:.1f}%")
            print("-" * 40)

        except Exception as e:
            print(f"ุฎุทุฃ ูู ูุนุงูุฌุฉ {svg_file}: {e}")
            continue

    if not all_results:
        print("ูู ูุชู ูุนุงูุฌุฉ ุฃู ููู ุจูุฌุงุญ")
        return 1

    # ุญูุธ ุงููุชุงุฆุฌ
    output_file = "precise_extraction_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)

    print(f"ุชู ุญูุธ ุงููุชุงุฆุฌ ูู: {output_file}")

    # ุฅุญุตุงุฆูุงุช ุดุงููุฉ
    total_accuracy = sum(r['statistics']['accuracy'] for r in all_results) / len(all_results)
    total_verses_matched = sum(r['statistics']['verses_matched'] for r in all_results)
    total_texts_extracted = sum(r['statistics']['total_texts'] for r in all_results)

    print(f"\n{'='*50}")
    print(f"ุงูุฅุญุตุงุฆูุงุช ุงูููุงุฆูุฉ:")
    print(f"{'='*50}")
    print(f"ุงููููุงุช ุงููุนุงูุฌุฉ: {processed_count}")
    print(f"ุฅุฌูุงูู ุงููุตูุต ุงููุณุชุฎุฑุฌุฉ: {total_texts_extracted}")
    print(f"ุฅุฌูุงูู ุงูุขูุงุช ุงููุทุงุจูุฉ: {total_verses_matched}")
    print(f"ุงูุฏูุฉ ุงูุฅุฌูุงููุฉ: {total_accuracy:.1f}%")

    if total_accuracy >= 95:
        print("๐ ุฏูุฉ ููุชุงุฒุฉ! ุงูุณูุฑูุจุช ูุนูู ุจููุงุกุฉ ุนุงููุฉ")
    elif total_accuracy >= 80:
        print("โ ุฏูุฉ ุฌูุฏุฉุ ูููู ุชุญุณูููุง ุฃูุซุฑ")
    else:
        print("โ๏ธ ุงูุฏูุฉ ููุฎูุถุฉุ ูุญุชุงุฌ ุชุญุณูู")

    return 0

if __name__ == "__main__":
    exit(main())
